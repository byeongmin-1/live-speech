<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Live Recorder — Live Notes</title>
  <style>
    :root{font-family:Inter, Roboto, -apple-system, BlinkMacSystemFont, "Segoe UI", Arial;}
    body{display:flex;flex-direction:column;align-items:center;padding:24px;background:#f6f8fb;color:#0b1220}
    .card{width:100%;max-width:900px;background:white;border-radius:12px;padding:18px;box-shadow:0 6px 20px rgba(12,20,40,0.08)}
    h1{margin:0 0 8px;font-size:22px}
    .controls{display:flex;gap:8px;flex-wrap:wrap;margin-bottom:12px}
    button{padding:10px 14px;border-radius:8px;border:1px solid #e6eef7;background:#fff;cursor:pointer}
    button.primary{background:#0b69ff;color:#fff;border:none}
    button:disabled{background:#ccc;color:#666;cursor:not-allowed}
    select{padding:8px;border-radius:8px;border:1px solid #e6eef7}
    #transcript{min-height:260px;border-radius:8px;padding:12px;border:1px dashed #dfe9ff;background:linear-gradient(180deg,#fff,#fbfdff);white-space:pre-wrap;overflow:auto}
    .meta{margin-top:10px;color:#4b5563;font-size:13px}
    footer{margin-top:10px;font-size:12px;color:#6b7280}
    .small{font-size:13px}
  </style>
</head>
<body>
  <div class="card">
    <h1>Live Recorder — Live Notes</h1>
    <p class="meta">Speak after pressing <strong>Start Recording</strong>. The app will transcribe live and keep time-coded segments (approximate). No uploads — everything runs in your browser.</p>

    <div class="controls">
      <button id="startBtn" class="primary">Start Recording</button>
      <button id="stopBtn">Stop</button>
      <button id="clearBtn">Clear</button>
      <button id="downloadTxtBtn">Download .txt</button>
      <button id="downloadSrtBtn">Download .srt</button>
      <button id="downloadAudioBtn">Download Audio</button>

      <label for="lang">Language:</label>
      <select id="lang" class="small">
        <option value="en-US">English (en-US)</option>
        <option value="ko-KR">한국어 (ko-KR)</option>
        <option value="vi-VN">Tiếng Việt (vi-VN)</option>
        <option value="ja-JP">日本語 (ja-JP)</option>
        <option value="zh-CN">中文 (zh-CN)</option>
      </select>

      <label style="display:flex;align-items:center;gap:6px;margin-left:8px"><input type="checkbox" id="interim" checked/> Show interim</label>
    </div>

    <div id="transcript" aria-live="polite" aria-atomic="false">(Live transcript will appear here)</div>
    <div class="meta" id="status">Status: idle</div>
    <footer>Note: Best experience on desktop Chrome/Edge. Your audio and text stay in this browser tab unless you download them.</footer>
  </div>

<script>
(function(){
  const startBtn = document.getElementById('startBtn');
  const stopBtn = document.getElementById('stopBtn');
  const clearBtn = document.getElementById('clearBtn');
  const downloadTxtBtn = document.getElementById('downloadTxtBtn');
  const downloadSrtBtn = document.getElementById('downloadSrtBtn');
  const downloadAudioBtn = document.getElementById('downloadAudioBtn');
  const transcriptEl = document.getElementById('transcript');
  const statusEl = document.getElementById('status');
  const langSel = document.getElementById('lang');
  const interimCheckbox = document.getElementById('interim');

  let recognition = null;
  let mediaRecorder = null;
  let mediaStream = null;
  let audioChunks = [];
  let recordingStart = null;
  let finalTranscript = '';
  let segments = [];
  let lastSegmentEnd = 0;

  function supportsSpeech(){
    return !!(window.SpeechRecognition || window.webkitSpeechRecognition);
  }

  function supportsMediaRecorder(){
    return !!(window.MediaRecorder);
  }

  function initSpeech(){
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    if(!SR) return null;
    const r = new SR();
    r.continuous = true;
    r.interimResults = true;
    r.maxAlternatives = 1;
    r.lang = langSel.value;
    return r;
  }

  async function startRecording(){
    startBtn.disabled = true;
    statusEl.textContent = 'Status: requesting microphone access...';

    if(!supportsSpeech()){
      alert('Your browser does not support the Web Speech API. Use Chrome or Edge on desktop.');
      startBtn.disabled = false;
      return;
    }

    // Check for HTTPS and secure context requirement
    if (location.protocol !== 'https:' && location.hostname !== 'localhost') {
      alert('Microphone access requires a secure context (HTTPS). Please host this file on https:// or use localhost.');
      statusEl.textContent = 'Status: insecure context (no mic access)';
      startBtn.disabled = false;
      return;
    }

    try{
      const stream = await navigator.mediaDevices.getUserMedia({audio:true});
      mediaStream = stream;
      audioChunks = [];

      if(supportsMediaRecorder()){
        try{
          mediaRecorder = new MediaRecorder(stream);
          mediaRecorder.ondataavailable = e => { if(e.data && e.data.size > 0) audioChunks.push(e.data); };
          mediaRecorder.start();
        }catch(e){
          console.warn('MediaRecorder start failed', e);
          mediaRecorder = null;
        }
      } else {
        console.warn('MediaRecorder not supported; audio will not be saved.');
      }

      recordingStart = Date.now();
      lastSegmentEnd = 0;
      segments = [];
      finalTranscript = '';
      transcriptEl.textContent = '';

      recognition = initSpeech();
      if(!recognition){
        statusEl.textContent = 'Status: SpeechRecognition not available';
        startBtn.disabled = false;
        return;
      }

      recognition.onstart = ()=>{
        statusEl.textContent = 'Status: recording & transcribing...';
      };

      recognition.onerror = (e)=>{
        console.error('recognition error', e);
        statusEl.textContent = 'Status: recognition error - ' + (e.error || e.message || 'unknown');
        startBtn.disabled = false;
      };

      recognition.onend = ()=>{
        statusEl.textContent = 'Status: recognition stopped';
        startBtn.disabled = false;
        recognition = null;
      };

      recognition.onresult = (event)=>{
        let interim = '';
        for(let i = event.resultIndex; i < event.results.length; i++){
          const res = event.results[i];
          const text = res[0].transcript.trim();
          if(res.isFinal){
            const now = Date.now();
            let startSec = lastSegmentEnd || 0;
            const durationGuess = Math.max(1, Math.min(6, Math.max(1, text.split(/\s+/).length * 0.25 + 1)));
            const endSec = startSec + durationGuess;
            segments.push({start: startSec, end: endSec, text});
            lastSegmentEnd = endSec;
            finalTranscript += (finalTranscript ? '\n' : '') + text;
          } else {
            interim += text + ' ';
          }
        }
        transcriptEl.textContent = finalTranscript + (interimCheckbox.checked ? '\n' + interim.trim() : '');
        transcriptEl.scrollTop = transcriptEl.scrollHeight;
      };

      recognition.lang = langSel.value;
      recognition.interimResults = interimCheckbox.checked;

      try{ recognition.start(); }catch(e){ console.warn(e); startBtn.disabled = false; }

      statusEl.textContent = 'Status: listening...';
    }catch(err){
      console.error('getUserMedia error', err);
      if (err.name === 'NotAllowedError' || err.name === 'SecurityError') {
        alert('Microphone access denied. Please allow microphone permissions in your browser settings and reload.');
      } else if (err.name === 'NotFoundError') {
        alert('No microphone detected. Please plug in a microphone and try again.');
      } else {
        alert('Could not access microphone: ' + (err && err.message ? err.message : err));
      }
      statusEl.textContent = 'Status: microphone access denied or unavailable';
      startBtn.disabled = false;
    }
  }

  function stopRecording(){
    if(mediaRecorder && mediaRecorder.state !== 'inactive'){
      try{ mediaRecorder.stop(); }catch(e){ console.warn('mediaRecorder.stop error', e); }
    }
    if(mediaStream){
      try{ mediaStream.getTracks().forEach(t=>t.stop()); }catch(e){}
      mediaStream = null;
    }
    if(recognition){
      try{ recognition.stop(); }catch(e){}
      recognition = null;
    }
    statusEl.textContent = 'Status: stopped';
    startBtn.disabled = false;
  }

  function clearAll(){
    finalTranscript = '';
    segments = [];
    lastSegmentEnd = 0;
    audioChunks = [];
    transcriptEl.textContent = '(Live transcript will appear here)';
    statusEl.textContent = 'Status: idle';
    startBtn.disabled = false;
  }

  function downloadTxt(){
    const text = finalTranscript || transcriptEl.textContent || '';
    const blob = new Blob([text], {type:'text/plain;charset=utf-8'});
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a'); a.href = url; a.download = 'transcript.txt'; document.body.appendChild(a); a.click(); a.remove(); URL.revokeObjectURL(url);
  }

  function secondsToSrtTime(s){
    let secFloat = Number(s) || 0;
    const h = Math.floor(secFloat/3600);
    secFloat -= h*3600;
    const m = Math.floor(secFloat/60);
    secFloat -= m*60;
    const sec = Math.floor(secFloat);
    const ms = Math.floor((secFloat - sec) * 1000);
    return `${String(h).padStart(2,'0')}:${String(m).padStart(2,'0')}:${String(sec).padStart(2,'0')},${String(ms).padStart(3,'0')}`;
  }

  function downloadSrt(){
    if(segments.length === 0){
      alert('No segments to create SRT from. Record something first.');
      return;
    }
    let srt = '';
    segments.forEach((seg,i)=>{
      srt += (i+1) + '\n';
      srt += secondsToSrtTime(seg.start) + ' --> ' + secondsToSrtTime(seg.end) + '\n';
      srt += seg.text + '\n\n';
    });
    const blob = new Blob([srt], {type:'text/plain;charset=utf-8'});
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a'); a.href = url; a.download = 'transcript.srt'; document.body.appendChild(a); a.click(); a.remove(); URL.revokeObjectURL(url);
  }

  function downloadAudio(){
    if(audioChunks.length === 0){
      alert('No audio recorded yet.');
      return;
    }
    const blob = new Blob(audioChunks, {type: audioChunks[0].type || 'audio/webm'});
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a'); a.href = url; a.download = 'recording.webm'; document.body.appendChild(a); a.click(); a.remove(); URL.revokeObjectURL(url);
  }

  startBtn.addEventListener('click', startRecording);
  stopBtn.addEventListener('click', stopRecording);
  clearBtn.addEventListener('click', clearAll);
  downloadTxtBtn.addEventListener('click', downloadTxt);
  downloadSrtBtn.addEventListener('click', downloadSrt);
  downloadAudioBtn.addEventListener('click', downloadAudio);
})();
</script>
</body>
</html>
